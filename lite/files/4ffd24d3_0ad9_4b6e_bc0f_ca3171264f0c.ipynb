{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "python"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "id": "6319fdeb",
            "cell_type": "markdown",
            "source": "<div class='alert alert-warning'>\n\nSciPy's interactive examples with Jupyterlite are experimental and may not always work as expected. Execution of cells containing imports may result in large downloads (up to 60MB of content for the first import from SciPy). Load times when importing from SciPy may take roughly 10-20 seconds. If you notice any problems, feel free to open an [issue](https://github.com/scipy/scipy/issues/new/choose).\n\n</div>",
            "metadata": {}
        },
        {
            "id": "fda937e1",
            "cell_type": "markdown",
            "source": "Suppose we wish to infer from measurements whether the weights of adult\nhuman males in a medical study are not normally distributed [2].\nThe weights (lbs) are recorded in the array ``x`` below.\n",
            "metadata": {}
        },
        {
            "id": "f80a146e",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "import numpy as np\nx = np.array([148, 154, 158, 160, 161, 162, 166, 170, 182, 195, 236])",
            "outputs": []
        },
        {
            "id": "d56de7f7",
            "cell_type": "markdown",
            "source": "The normality test of [1] and [2] begins by computing a statistic based\non the relationship between the observations and the expected order\nstatistics of a normal distribution.\n",
            "metadata": {}
        },
        {
            "id": "c155e4ec",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "from scipy import stats\nres = stats.shapiro(x)\nres.statistic",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.7888147830963135"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "23ba2b4e",
            "cell_type": "markdown",
            "source": "The value of this statistic tends to be high (close to 1) for samples drawn\nfrom a normal distribution.\n\nThe test is performed by comparing the observed value of the statistic\nagainst the null distribution: the distribution of statistic values formed\nunder the null hypothesis that the weights were drawn from a normal\ndistribution. For this normality test, the null distribution is not easy to\ncalculate exactly, so it is usually approximated by Monte Carlo methods,\nthat is, drawing many samples of the same size as ``x`` from a normal\ndistribution and computing the values of the statistic for each.\n",
            "metadata": {}
        },
        {
            "id": "8544fc47",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "def statistic(x):\n    # Get only the `shapiro` statistic; ignore its p-value\n    return stats.shapiro(x).statistic\nref = stats.monte_carlo_test(x, stats.norm.rvs, statistic,\n                             alternative='less')\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(figsize=(8, 5))\nbins = np.linspace(0.65, 1, 50)\ndef plot(ax):  # we'll reuse this\n    ax.hist(ref.null_distribution, density=True, bins=bins)\n    ax.set_title(\"Shapiro-Wilk Test Null Distribution \\n\"\n                 \"(Monte Carlo Approximation, 11 Observations)\")\n    ax.set_xlabel(\"statistic\")\n    ax.set_ylabel(\"probability density\")\nplot(ax)\nplt.show()",
            "outputs": []
        },
        {
            "id": "f60b51b6",
            "cell_type": "markdown",
            "source": "The comparison is quantified by the p-value: the proportion of values in\nthe null distribution less than or equal to the observed value of the\nstatistic.\n",
            "metadata": {}
        },
        {
            "id": "a28effb0",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "fig, ax = plt.subplots(figsize=(8, 5))\nplot(ax)\nannotation = (f'p-value={res.pvalue:.6f}\\n(highlighted area)')\nprops = dict(facecolor='black', width=1, headwidth=5, headlength=8)\n_ = ax.annotate(annotation, (0.75, 0.1), (0.68, 0.7), arrowprops=props)\ni_extreme = np.where(bins <= res.statistic)[0]\nfor i in i_extreme:\n    ax.patches[i].set_color('C1')\nplt.xlim(0.65, 0.9)\nplt.ylim(0, 4)\nplt.show\nres.pvalue",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.006703833118081093"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "389906f2",
            "cell_type": "markdown",
            "source": "If the p-value is \"small\" - that is, if there is a low probability of\nsampling data from a normally distributed population that produces such an\nextreme value of the statistic - this may be taken as evidence against\nthe null hypothesis in favor of the alternative: the weights were not\ndrawn from a normal distribution. Note that:\n\n- The inverse is not true; that is, the test is not used to provide\n  evidence *for* the null hypothesis.\n- The threshold for values that will be considered \"small\" is a choice that\n  should be made before the data is analyzed [5] with consideration of the\n  risks of both false positives (incorrectly rejecting the null hypothesis)\n  and false negatives (failure to reject a false null hypothesis).\n",
            "metadata": {}
        }
    ]
}