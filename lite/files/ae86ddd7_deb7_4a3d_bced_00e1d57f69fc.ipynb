{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "python"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "id": "4eaaf6cb",
            "cell_type": "markdown",
            "source": "<div class='alert alert-warning'>\n\nSciPy's interactive examples with Jupyterlite are experimental and may not always work as expected. Execution of cells containing imports may result in large downloads (up to 60MB of content for the first import from SciPy). Load times when importing from SciPy may take roughly 10-20 seconds. If you notice any problems, feel free to open an [issue](https://github.com/scipy/scipy/issues/new/choose).\n\n</div>",
            "metadata": {}
        },
        {
            "id": "751a04df",
            "cell_type": "markdown",
            "source": "Suppose we have sampled data from an unknown distribution.\n",
            "metadata": {}
        },
        {
            "id": "b28fc842",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "import numpy as np\nrng = np.random.default_rng()\nfrom scipy.stats import norm\ndist = norm(loc=2, scale=4)  # our \"unknown\" distribution\ndata = dist.rvs(size=100, random_state=rng)",
            "outputs": []
        },
        {
            "id": "b5b3a62c",
            "cell_type": "markdown",
            "source": "We are interested in the standard deviation of the distribution.\n",
            "metadata": {}
        },
        {
            "id": "45b1483f",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "std_true = dist.std()      # the true value of the statistic\nprint(std_true)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "4.0"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "3c23ff11",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "std_sample = np.std(data)  # the sample statistic\nprint(std_sample)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "3.9460644295563863"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "f1beb83d",
            "cell_type": "markdown",
            "source": "The bootstrap is used to approximate the variability we would expect if we\nwere to repeatedly sample from the unknown distribution and calculate the\nstatistic of the sample each time. It does this by repeatedly resampling\nvalues *from the original sample* with replacement and calculating the\nstatistic of each resample. This results in a \"bootstrap distribution\" of\nthe statistic.\n",
            "metadata": {}
        },
        {
            "id": "353578eb",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "import matplotlib.pyplot as plt\nfrom scipy.stats import bootstrap\ndata = (data,)  # samples must be in a sequence\nres = bootstrap(data, np.std, confidence_level=0.9,\n                random_state=rng)\nfig, ax = plt.subplots()\nax.hist(res.bootstrap_distribution, bins=25)\nax.set_title('Bootstrap Distribution')\nax.set_xlabel('statistic value')\nax.set_ylabel('frequency')\nplt.show()",
            "outputs": []
        },
        {
            "id": "95101c91",
            "cell_type": "markdown",
            "source": "The standard error quantifies this variability. It is calculated as the\nstandard deviation of the bootstrap distribution.\n",
            "metadata": {}
        },
        {
            "id": "edbaeacc",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "res.standard_error",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.24427002125829136"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "2c3bc479",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "res.standard_error == np.std(res.bootstrap_distribution, ddof=1)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "True"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "d5f9020a",
            "cell_type": "markdown",
            "source": "The bootstrap distribution of the statistic is often approximately normal\nwith scale equal to the standard error.\n",
            "metadata": {}
        },
        {
            "id": "827a450c",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "x = np.linspace(3, 5)\npdf = norm.pdf(x, loc=std_sample, scale=res.standard_error)\nfig, ax = plt.subplots()\nax.hist(res.bootstrap_distribution, bins=25, density=True)\nax.plot(x, pdf)\nax.set_title('Normal Approximation of the Bootstrap Distribution')\nax.set_xlabel('statistic value')\nax.set_ylabel('pdf')\nplt.show()",
            "outputs": []
        },
        {
            "id": "141b01ad",
            "cell_type": "markdown",
            "source": "This suggests that we could construct a 90% confidence interval on the\nstatistic based on quantiles of this normal distribution.\n",
            "metadata": {}
        },
        {
            "id": "d6a706bd",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "norm.interval(0.9, loc=std_sample, scale=res.standard_error)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "(3.5442759991341726, 4.3478528599786)"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "62d4f088",
            "cell_type": "markdown",
            "source": "Due to central limit theorem, this normal approximation is accurate for a\nvariety of statistics and distributions underlying the samples; however,\nthe approximation is not reliable in all cases. Because `bootstrap` is\ndesigned to work with arbitrary underlying distributions and statistics,\nit uses more advanced techniques to generate an accurate confidence\ninterval.\n",
            "metadata": {}
        },
        {
            "id": "f4ae925d",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "print(res.confidence_interval)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "ConfidenceInterval(low=3.57655333533867, high=4.382043696342881)"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "3b68f93d",
            "cell_type": "markdown",
            "source": "If we sample from the original distribution 1000 times and form a bootstrap\nconfidence interval for each sample, the confidence interval\ncontains the true value of the statistic approximately 90% of the time.\n",
            "metadata": {}
        },
        {
            "id": "6fe470ab",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "n_trials = 1000\nci_contains_true_std = 0\nfor i in range(n_trials):\n   data = (dist.rvs(size=100, random_state=rng),)\n   ci = bootstrap(data, np.std, confidence_level=0.9, n_resamples=1000,\n                  random_state=rng).confidence_interval\n   if ci[0] < std_true < ci[1]:\n       ci_contains_true_std += 1\nprint(ci_contains_true_std)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "875"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "1d6a108a",
            "cell_type": "markdown",
            "source": "Rather than writing a loop, we can also determine the confidence intervals\nfor all 1000 samples at once.\n",
            "metadata": {}
        },
        {
            "id": "c92742bd",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "data = (dist.rvs(size=(n_trials, 100), random_state=rng),)\nres = bootstrap(data, np.std, axis=-1, confidence_level=0.9,\n                n_resamples=1000, random_state=rng)\nci_l, ci_u = res.confidence_interval",
            "outputs": []
        },
        {
            "id": "0ace7bb8",
            "cell_type": "markdown",
            "source": "Here, `ci_l` and `ci_u` contain the confidence interval for each of the\n``n_trials = 1000`` samples.\n",
            "metadata": {}
        },
        {
            "id": "5458107e",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "print(ci_l[995:])",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "[3.77729695 3.75090233 3.45829131 3.34078217 3.48072829]"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "4f45e7ef",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "print(ci_u[995:])",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "[4.88316666 4.86924034 4.32032996 4.2822427  4.59360598]"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "d31e79d0",
            "cell_type": "markdown",
            "source": "And again, approximately 90% contain the true value, ``std_true = 4``.\n",
            "metadata": {}
        },
        {
            "id": "326cefa7",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "print(np.sum((ci_l < std_true) & (std_true < ci_u)))",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "900"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "695da929",
            "cell_type": "markdown",
            "source": "`bootstrap` can also be used to estimate confidence intervals of\nmulti-sample statistics, including those calculated by hypothesis\ntests. `scipy.stats.mood` perform's Mood's test for equal scale parameters,\nand it returns two outputs: a statistic, and a p-value. To get a\nconfidence interval for the test statistic, we first wrap\n`scipy.stats.mood` in a function that accepts two sample arguments,\naccepts an `axis` keyword argument, and returns only the statistic.\n",
            "metadata": {}
        },
        {
            "id": "72978def",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "from scipy.stats import mood\ndef my_statistic(sample1, sample2, axis):\n    statistic, _ = mood(sample1, sample2, axis=-1)\n    return statistic",
            "outputs": []
        },
        {
            "id": "a2e4c6de",
            "cell_type": "markdown",
            "source": "Here, we use the 'percentile' method with the default 95% confidence level.\n",
            "metadata": {}
        },
        {
            "id": "0b015bdc",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "sample1 = norm.rvs(scale=1, size=100, random_state=rng)\nsample2 = norm.rvs(scale=2, size=100, random_state=rng)\ndata = (sample1, sample2)\nres = bootstrap(data, my_statistic, method='basic', random_state=rng)\nprint(mood(sample1, sample2)[0])  # element 0 is the statistic",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "-5.521109549096542"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "39f02f8f",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "print(res.confidence_interval)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "ConfidenceInterval(low=-7.255994487314675, high=-4.016202624747605)"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "bd98eee7",
            "cell_type": "markdown",
            "source": "The bootstrap estimate of the standard error is also available.\n",
            "metadata": {}
        },
        {
            "id": "a272876d",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "print(res.standard_error)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.8344963846318795"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "ec6e69f2",
            "cell_type": "markdown",
            "source": "Paired-sample statistics work, too. For example, consider the Pearson\ncorrelation coefficient.\n",
            "metadata": {}
        },
        {
            "id": "e131ddda",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "from scipy.stats import pearsonr\nn = 100\nx = np.linspace(0, 10, n)\ny = x + rng.uniform(size=n)\nprint(pearsonr(x, y)[0])  # element 0 is the statistic",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.9962357936065914"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "0eee0f6b",
            "cell_type": "markdown",
            "source": "We wrap `pearsonr` so that it returns only the statistic.\n",
            "metadata": {}
        },
        {
            "id": "4763c012",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "def my_statistic(x, y):\n    return pearsonr(x, y)[0]",
            "outputs": []
        },
        {
            "id": "7fdea914",
            "cell_type": "markdown",
            "source": "We call `bootstrap` using ``paired=True``.\nAlso, since ``my_statistic`` isn't vectorized to calculate the statistic\nalong a given axis, we pass in ``vectorized=False``.\n",
            "metadata": {}
        },
        {
            "id": "e0cae39b",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "res = bootstrap((x, y), my_statistic, vectorized=False, paired=True,\n                random_state=rng)\nprint(res.confidence_interval)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "ConfidenceInterval(low=0.9950085825848624, high=0.9971212407917498)"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "717a0fa1",
            "cell_type": "markdown",
            "source": "The result object can be passed back into `bootstrap` to perform additional\nresampling:\n",
            "metadata": {}
        },
        {
            "id": "ff53676c",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "len(res.bootstrap_distribution)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "9999"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "249fee71",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "res = bootstrap((x, y), my_statistic, vectorized=False, paired=True,\n                n_resamples=1001, random_state=rng,\n                bootstrap_result=res)\nlen(res.bootstrap_distribution)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "11000"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "74c8d776",
            "cell_type": "markdown",
            "source": "or to change the confidence interval options:\n",
            "metadata": {}
        },
        {
            "id": "bd3abbec",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "res2 = bootstrap((x, y), my_statistic, vectorized=False, paired=True,\n                 n_resamples=0, random_state=rng, bootstrap_result=res,\n                 method='percentile', confidence_level=0.9)\nnp.testing.assert_equal(res2.bootstrap_distribution,\n                        res.bootstrap_distribution)\nres.confidence_interval",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "ConfidenceInterval(low=0.9950035351407804, high=0.9971170323404578)"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "4b8285fe",
            "cell_type": "markdown",
            "source": "without repeating computation of the original bootstrap distribution.\n",
            "metadata": {}
        }
    ]
}