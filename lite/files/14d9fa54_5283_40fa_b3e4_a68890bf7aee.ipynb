{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "python"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "id": "0cbe759f",
            "cell_type": "markdown",
            "source": "<div class='alert alert-warning'>\n\nSciPy's interactive examples with Jupyterlite are experimental and may not always work as expected. Execution of cells containing imports may result in large downloads (up to 60MB of content for the first import from SciPy). Load times when importing from SciPy may take roughly 10-20 seconds. If you notice any problems, feel free to open an [issue](https://github.com/scipy/scipy/issues/new/choose).\n\n</div>",
            "metadata": {}
        },
        {
            "id": "27e7b295",
            "cell_type": "markdown",
            "source": "In [9], a Latin Hypercube sampling strategy was used to sample a\nparameter space to study the importance of each parameter of an epidemic\nmodel. Such analysis is also called a sensitivity analysis.\n\nSince the dimensionality of the problem is high (6), it is computationally\nexpensive to cover the space. When numerical experiments are costly,\nQMC enables analysis that may not be possible if using a grid.\n\nThe six parameters of the model represented the probability of illness,\nthe probability of withdrawal, and four contact probabilities,\nThe authors assumed uniform distributions for all parameters and generated\n50 samples.\n\nUsing `scipy.stats.qmc.LatinHypercube` to replicate the protocol, the\nfirst step is to create a sample in the unit hypercube:\n",
            "metadata": {}
        },
        {
            "id": "31ae47d8",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "from scipy.stats import qmc\nsampler = qmc.LatinHypercube(d=6)\nsample = sampler.random(n=50)",
            "outputs": []
        },
        {
            "id": "43b81fb1",
            "cell_type": "markdown",
            "source": "Then the sample can be scaled to the appropriate bounds:\n",
            "metadata": {}
        },
        {
            "id": "752caad4",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "l_bounds = [0.000125, 0.01, 0.0025, 0.05, 0.47, 0.7]\nu_bounds = [0.000375, 0.03, 0.0075, 0.15, 0.87, 0.9]\nsample_scaled = qmc.scale(sample, l_bounds, u_bounds)",
            "outputs": []
        },
        {
            "id": "146d5d94",
            "cell_type": "markdown",
            "source": "Such a sample was used to run the model 50 times, and a polynomial\nresponse surface was constructed. This allowed the authors to study the\nrelative importance of each parameter across the range of\npossibilities of every other parameter.\nIn this computer experiment, they showed a 14-fold reduction in the number\nof samples required to maintain an error below 2% on their response surface\nwhen compared to a grid sampling.\n\nBelow are other examples showing alternative ways to construct LHS\nwith even better coverage of the space.\n\nUsing a base LHS as a baseline.\n",
            "metadata": {}
        },
        {
            "id": "9c59f8ec",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "sampler = qmc.LatinHypercube(d=2)\nsample = sampler.random(n=5)\nqmc.discrepancy(sample)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.0196...  # random"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "24a35fd1",
            "cell_type": "markdown",
            "source": "Use the `optimization` keyword argument to produce a LHS with\nlower discrepancy at higher computational cost.\n",
            "metadata": {}
        },
        {
            "id": "499f1ca3",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "sampler = qmc.LatinHypercube(d=2, optimization=\"random-cd\")\nsample = sampler.random(n=5)\nqmc.discrepancy(sample)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.0176...  # random"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "9194950a",
            "cell_type": "markdown",
            "source": "Use the `strength` keyword argument to produce an orthogonal array based\nLHS of strength 2. In this case, the number of sample points must be the\nsquare of a prime number.\n",
            "metadata": {}
        },
        {
            "id": "36827ae4",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "sampler = qmc.LatinHypercube(d=2, strength=2)\nsample = sampler.random(n=9)\nqmc.discrepancy(sample)",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.00526...  # random"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "d3bb0476",
            "cell_type": "markdown",
            "source": "Options could be combined to produce an optimized centered\northogonal array based LHS. After optimization, the result would not\nbe guaranteed to be of strength 2.",
            "metadata": {}
        }
    ]
}