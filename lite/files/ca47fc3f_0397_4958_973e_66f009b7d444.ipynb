{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "python"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "id": "493c27d9",
            "cell_type": "markdown",
            "source": "<div class='alert alert-warning'>\n\nSciPy's interactive examples with Jupyterlite are experimental and may not always work as expected. Execution of cells containing imports may result in large downloads (up to 60MB of content for the first import from SciPy). Load times when importing from SciPy may take roughly 10-20 seconds. If you notice any problems, feel free to open an [issue](https://github.com/scipy/scipy/issues/new/choose).\n\n</div>",
            "metadata": {}
        },
        {
            "id": "5a341b98",
            "cell_type": "markdown",
            "source": "Consider the following data from [6], which studied the relationship\nbetween free proline (an amino acid) and total collagen (a protein often\nfound in connective tissue) in unhealthy human livers.\n\nThe ``x`` and ``y`` arrays below record measurements of the two compounds.\nThe observations are paired: each free proline measurement was taken from\nthe same liver as the total collagen measurement at the same index.\n",
            "metadata": {}
        },
        {
            "id": "0d75a9d7",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "import numpy as np\n# total collagen (mg/g dry weight of liver)\nx = np.array([7.1, 7.1, 7.2, 8.3, 9.4, 10.5, 11.4])\n# free proline (Î¼ mole/g dry weight of liver)\ny = np.array([2.8, 2.9, 2.8, 2.6, 3.5, 4.6, 5.0])",
            "outputs": []
        },
        {
            "id": "7ba55778",
            "cell_type": "markdown",
            "source": "These data were analyzed in [7] using Spearman's correlation coefficient,\na statistic similar to to Kendall's tau in that it is also sensitive to\nordinal correlation between the samples. Let's perform an analogous study\nusing Kendall's tau.\n",
            "metadata": {}
        },
        {
            "id": "c57b967e",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "from scipy import stats\nres = stats.kendalltau(x, y)\nres.statistic",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.5499999999999999"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "2684823a",
            "cell_type": "markdown",
            "source": "The value of this statistic tends to be high (close to 1) for samples with\na strongly positive ordinal correlation, low (close to -1) for samples with\na strongly negative ordinal correlation, and small in magnitude (close to\nzero) for samples with weak ordinal correlation.\n\nThe test is performed by comparing the observed value of the\nstatistic against the null distribution: the distribution of statistic\nvalues derived under the null hypothesis that total collagen and free\nproline measurements are independent.\n\nFor this test, the null distribution for large samples without ties is\napproximated as the normal distribution with variance\n``(2*(2*n + 5))/(9*n*(n - 1))``, where ``n = len(x)``.\n",
            "metadata": {}
        },
        {
            "id": "a60b8a8f",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "import matplotlib.pyplot as plt\nn = len(x)  # len(x) == len(y)\nvar = (2*(2*n + 5))/(9*n*(n - 1))\ndist = stats.norm(scale=np.sqrt(var))\nz_vals = np.linspace(-1.25, 1.25, 100)\npdf = dist.pdf(z_vals)\nfig, ax = plt.subplots(figsize=(8, 5))\ndef plot(ax):  # we'll reuse this\n    ax.plot(z_vals, pdf)\n    ax.set_title(\"Kendall Tau Test Null Distribution\")\n    ax.set_xlabel(\"statistic\")\n    ax.set_ylabel(\"probability density\")\nplot(ax)\nplt.show()",
            "outputs": []
        },
        {
            "id": "0bf5fc25",
            "cell_type": "markdown",
            "source": "The comparison is quantified by the p-value: the proportion of values in\nthe null distribution as extreme or more extreme than the observed\nvalue of the statistic. In a two-sided test in which the statistic is\npositive, elements of the null distribution greater than the transformed\nstatistic and elements of the null distribution less than the negative of\nthe observed statistic are both considered \"more extreme\".\n",
            "metadata": {}
        },
        {
            "id": "db01efd2",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "fig, ax = plt.subplots(figsize=(8, 5))\nplot(ax)\npvalue = dist.cdf(-res.statistic) + dist.sf(res.statistic)\nannotation = (f'p-value={pvalue:.4f}\\n(shaded area)')\nprops = dict(facecolor='black', width=1, headwidth=5, headlength=8)\n_ = ax.annotate(annotation, (0.65, 0.15), (0.8, 0.3), arrowprops=props)\ni = z_vals >= res.statistic\nax.fill_between(z_vals[i], y1=0, y2=pdf[i], color='C0')\ni = z_vals <= -res.statistic\nax.fill_between(z_vals[i], y1=0, y2=pdf[i], color='C0')\nax.set_xlim(-1.25, 1.25)\nax.set_ylim(0, 0.5)\nplt.show()",
            "outputs": []
        },
        {
            "id": "9506b394",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "res.pvalue",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.09108705741631495  # approximate p-value"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "9642cfed",
            "cell_type": "markdown",
            "source": "Note that there is slight disagreement between the shaded area of the curve\nand the p-value returned by `kendalltau`. This is because our data has\nties, and we have neglected a tie correction to the null distribution\nvariance that `kendalltau` performs. For samples without ties, the shaded\nareas of our plot and p-value returned by `kendalltau` would match exactly.\n\nIf the p-value is \"small\" - that is, if there is a low probability of\nsampling data from independent distributions that produces such an extreme\nvalue of the statistic - this may be taken as evidence against the null\nhypothesis in favor of the alternative: the distribution of total collagen\nand free proline are *not* independent. Note that:\n\n- The inverse is not true; that is, the test is not used to provide\n  evidence for the null hypothesis.\n- The threshold for values that will be considered \"small\" is a choice that\n  should be made before the data is analyzed [8] with consideration of the\n  risks of both false positives (incorrectly rejecting the null hypothesis)\n  and false negatives (failure to reject a false null hypothesis).\n- Small p-values are not evidence for a *large* effect; rather, they can\n  only provide evidence for a \"significant\" effect, meaning that they are\n  unlikely to have occurred under the null hypothesis.\n\nFor samples without ties of moderate size, `kendalltau` can compute the\np-value exactly. However, in the presence of ties, `kendalltau` resorts\nto an asymptotic approximation. Nonetheles, we can use a permutation test\nto compute the null distribution exactly: Under the null hypothesis that\ntotal collagen and free proline are independent, each of the free proline\nmeasurements were equally likely to have been observed with any of the\ntotal collagen measurements. Therefore, we can form an *exact* null\ndistribution by calculating the statistic under each possible pairing of\nelements between ``x`` and ``y``.\n",
            "metadata": {}
        },
        {
            "id": "e9358cf1",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "def statistic(x):  # explore all possible pairings by permuting `x`\n    return stats.kendalltau(x, y).statistic  # ignore pvalue\nref = stats.permutation_test((x,), statistic,\n                             permutation_type='pairings')\nfig, ax = plt.subplots(figsize=(8, 5))\nplot(ax)\nbins = np.linspace(-1.25, 1.25, 25)\nax.hist(ref.null_distribution, bins=bins, density=True)\nax.legend(['aymptotic approximation\\n(many observations)',\n           'exact null distribution'])\nplot(ax)\nplt.show()",
            "outputs": []
        },
        {
            "id": "82678128",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "ref.pvalue",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.12222222222222222  # exact p-value"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "4779868e",
            "cell_type": "markdown",
            "source": "Note that there is significant disagreement between the exact p-value\ncalculated here and the approximation returned by `kendalltau` above. For\nsmall samples with ties, consider performing a permutation test for more\naccurate results.\n",
            "metadata": {}
        }
    ]
}