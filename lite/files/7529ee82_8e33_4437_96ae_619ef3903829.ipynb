{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "python"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "id": "436be7f2",
            "cell_type": "markdown",
            "source": "<div class='alert alert-warning'>\n\nSciPy's interactive examples with Jupyterlite are experimental and may not always work as expected. Execution of cells containing imports may result in large downloads (up to 60MB of content for the first import from SciPy). Load times when importing from SciPy may take roughly 10-20 seconds. If you notice any problems, feel free to open an [issue](https://github.com/scipy/scipy/issues/new/choose).\n\n</div>",
            "metadata": {}
        },
        {
            "id": "3d2d2dd7",
            "cell_type": "markdown",
            "source": "Suppose we wish to infer from measurements whether the weights of adult\nhuman males in a medical study are not normally distributed [2].\nThe weights (lbs) are recorded in the array ``x`` below.\n",
            "metadata": {}
        },
        {
            "id": "6bcbc217",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "import numpy as np\nx = np.array([148, 154, 158, 160, 161, 162, 166, 170, 182, 195, 236])",
            "outputs": []
        },
        {
            "id": "b3a2b023",
            "cell_type": "markdown",
            "source": "The skewness test from [1] begins by computing a statistic based on the\nsample skewness.\n",
            "metadata": {}
        },
        {
            "id": "953e8506",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "from scipy import stats\nres = stats.skewtest(x)\nres.statistic",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "2.7788579769903414"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "40ef92fb",
            "cell_type": "markdown",
            "source": "Because normal distributions have zero skewness, the magnitude of this\nstatistic tends to be low for samples drawn from a normal distribution.\n\nThe test is performed by comparing the observed value of the\nstatistic against the null distribution: the distribution of statistic\nvalues derived under the null hypothesis that the weights were drawn from\na normal distribution.\n\nFor this test, the null distribution of the statistic for very large\nsamples is the standard normal distribution.\n",
            "metadata": {}
        },
        {
            "id": "0a1c2ae7",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "import matplotlib.pyplot as plt\ndist = stats.norm()\nst_val = np.linspace(-5, 5, 100)\npdf = dist.pdf(st_val)\nfig, ax = plt.subplots(figsize=(8, 5))\ndef st_plot(ax):  # we'll reuse this\n    ax.plot(st_val, pdf)\n    ax.set_title(\"Skew Test Null Distribution\")\n    ax.set_xlabel(\"statistic\")\n    ax.set_ylabel(\"probability density\")\nst_plot(ax)\nplt.show()",
            "outputs": []
        },
        {
            "id": "6f6464d4",
            "cell_type": "markdown",
            "source": "The comparison is quantified by the p-value: the proportion of values in\nthe null distribution as extreme or more extreme than the observed\nvalue of the statistic. In a two-sided test, elements of the null\ndistribution greater than the observed statistic and elements of the null\ndistribution less than the negative of the observed statistic are both\nconsidered \"more extreme\".\n",
            "metadata": {}
        },
        {
            "id": "22c3daa4",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "fig, ax = plt.subplots(figsize=(8, 5))\nst_plot(ax)\npvalue = dist.cdf(-res.statistic) + dist.sf(res.statistic)\nannotation = (f'p-value={pvalue:.3f}\\n(shaded area)')\nprops = dict(facecolor='black', width=1, headwidth=5, headlength=8)\n_ = ax.annotate(annotation, (3, 0.005), (3.25, 0.02), arrowprops=props)\ni = st_val >= res.statistic\nax.fill_between(st_val[i], y1=0, y2=pdf[i], color='C0')\ni = st_val <= -res.statistic\nax.fill_between(st_val[i], y1=0, y2=pdf[i], color='C0')\nax.set_xlim(-5, 5)\nax.set_ylim(0, 0.1)\nplt.show()",
            "outputs": []
        },
        {
            "id": "604cfae7",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "res.pvalue",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.005455036974740185"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "ab19ad6a",
            "cell_type": "markdown",
            "source": "If the p-value is \"small\" - that is, if there is a low probability of\nsampling data from a normally distributed population that produces such an\nextreme value of the statistic - this may be taken as evidence against\nthe null hypothesis in favor of the alternative: the weights were not\ndrawn from a normal distribution. Note that:\n\n- The inverse is not true; that is, the test is not used to provide\n  evidence for the null hypothesis.\n- The threshold for values that will be considered \"small\" is a choice that\n  should be made before the data is analyzed [3] with consideration of the\n  risks of both false positives (incorrectly rejecting the null hypothesis)\n  and false negatives (failure to reject a false null hypothesis).\n\nNote that the standard normal distribution provides an asymptotic\napproximation of the null distribution; it is only accurate for samples\nwith many observations. For small samples like ours,\n`scipy.stats.monte_carlo_test` may provide a more accurate, albeit\nstochastic, approximation of the exact p-value.\n",
            "metadata": {}
        },
        {
            "id": "f10ff3c5",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "def statistic(x, axis):\n    # get just the skewtest statistic; ignore the p-value\n    return stats.skewtest(x, axis=axis).statistic\nres = stats.monte_carlo_test(x, stats.norm.rvs, statistic)\nfig, ax = plt.subplots(figsize=(8, 5))\nst_plot(ax)\nax.hist(res.null_distribution, np.linspace(-5, 5, 50),\n        density=True)\nax.legend(['aymptotic approximation\\n(many observations)',\n           'Monte Carlo approximation\\n(11 observations)'])\nplt.show()",
            "outputs": []
        },
        {
            "id": "842af698",
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "source": "res.pvalue",
            "outputs": [
                {
                    "output_type": "execute_result",
                    "metadata": {},
                    "data": {
                        "text/plain": "0.0062  # may vary"
                    },
                    "execution_count": null
                }
            ]
        },
        {
            "id": "32514570",
            "cell_type": "markdown",
            "source": "In this case, the asymptotic approximation and Monte Carlo approximation\nagree fairly closely, even for our small sample.\n",
            "metadata": {}
        }
    ]
}